
@incollection{kim_automated_2010,
	address = {Berlin},
	title = {Automated {Hedcut} {Illustration} {Using} {Isophotes}},
	volume = {6133},
	isbn = {978-3-642-13544-6},
	url = {https://doi.org/10.1007/978-3-642-13544-6_17},
	abstract = {In this work, we present an automated system for creating hedcut illustrations, portraits rendered using small image feature aligned dots (stipples). We utilize edge detection and shading cues from the input photograph to direct stipple placement within the image. Both image edges and isophotes are extracted as a means of describing the image feature and shading information. Edge features and isophotes are then assigned diﬀerent priorities, with isophotes being assigned the highest priority to enhance the depth perception within the hedcut portrait. Priority assignment dictates the stipple alignment and spacing. Finally, stipple size is based on the number of points and intensity and the gradient magnitude of the input image.},
	language = {en},
	booktitle = {International {Symposium} on {Smart} {Graphics}},
	publisher = {Spinger},
	author = {Kim, SungYe and Woo, Insoo and Maciejewski, Ross and Ebert, David S},
	month = jun,
	year = {2010},
	pages = {12},
	file = {Kim et al. - Automated Hedcut Illustration Using Isophotes.pdf:/Users/ariakillebrewbruehl/Zotero/storage/NSSA5ZXS/Kim et al. - Automated Hedcut Illustration Using Isophotes.pdf:application/pdf},
}

@misc{anderson_whats_2019,
	title = {What’s in a {Hedcut}? {Depends} {How} {It}’s {Made}.},
	shorttitle = {What’s in a {Hedcut}?},
	url = {https://www.wsj.com/articles/whats-in-a-hedcut-depends-how-its-made-11576537243},
	abstract = {The Wall Street Journal is offering members a chance to upload their photos to our hedcut-generating tool, which uses artificial intelligence to replicate the hand-drawn images that have accompanied our journalism for the past 40 years.},
	language = {en-US},
	urldate = {2022-11-01},
	journal = {WSJ},
	author = {Anderson, Emily and Marconi, Francesco and Reynolds, Carrie},
	month = dec,
	year = {2019},
	note = {Section: US},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/3G5QEJK2/whats-in-a-hedcut-depends-how-its-made-11576537243.html:text/html},
}

@book{gooch_non-photorealistic_2001,
	title = {Non-{Photorealistic} {Rendering}},
	isbn = {1-56881-133-0},
	publisher = {A K Peters, Ltd.},
	author = {Gooch, Bruce and Gooch, Amy},
	year = {2001},
}

@article{son_structure_2011,
	title = {Structure grid for directional stippling},
	volume = {73},
	issn = {15240703},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1524070310000433},
	doi = {10.1016/j.gmod.2010.12.001},
	abstract = {This paper presents a novel method to convert a photograph into a stipple illustration. Our method addresses directional stippling, where the collective ﬂows of dots are directed parallel and/or orthogonal to the local feature orientations. To facilitate regular and directional spacing of dots, we introduce the notion of a structure grid, which is extracted from the smoothed feature orientation ﬁeld. We represent a structure grid as a 2D texture and develop an efﬁcient construction algorithm that outperforms conventional Lloyd’s method in terms of the rigor of dot alignment. Moreover, the criss-crossing nature of a structure grid allows for the inclusion of line primitives, providing effective description of dark tone. Given a structure grid, we determine the appropriate positions and attributes of primitives in the ﬁnal illustration via rapid pixel-based primitive rendering. Experimental results show that our directional stippling method nicely reproduces features and tones of various input images.},
	language = {en},
	number = {3},
	urldate = {2022-11-04},
	journal = {Graphical Models},
	author = {Son, Minjung and Lee, Yunjin and Kang, Henry and Lee, Seungyong},
	month = may,
	year = {2011},
	pages = {74--87},
	file = {Son et al. - 2011 - Structure grid for directional stippling.pdf:/Users/ariakillebrewbruehl/Zotero/storage/BPKG59T4/Son et al. - 2011 - Structure grid for directional stippling.pdf:application/pdf},
}

@article{roose_i-generated_2022,
	chapter = {Technology},
	title = {An {A}.{I}.-{Generated} {Picture} {Won} an {Art} {Prize}. {Artists} {Aren}’t {Happy}.},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html},
	abstract = {“I won, and I didn’t break any rules,” the artwork’s creator says.},
	language = {en-US},
	urldate = {2022-11-07},
	journal = {The New York Times},
	author = {Roose, Kevin},
	month = sep,
	year = {2022},
	keywords = {Art, Artificial Intelligence, Colorado, Contests and Prizes, emergingtech, Midjourney Inc, State and County Fairs},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/VHK98LUN/ai-artificial-intelligence-artists.html:text/html},
}

@misc{arpin-ricci_ethics_2022,
	title = {The {Ethics} of {AI} {Generated} {Art}},
	url = {https://jamiearpinricci.medium.com/the-ethics-of-ai-generated-art-57fb04b71646},
	abstract = {Chances are you’ve already seen the headline (or some variation thereof):},
	language = {en},
	urldate = {2022-11-07},
	journal = {Medium},
	author = {Arpin-Ricci, Jamie},
	month = sep,
	year = {2022},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/TRRTWW45/the-ethics-of-ai-generated-art-57fb04b71646.html:text/html},
}

@book{niblack_introduction_1986,
	address = {Denmark},
	title = {An {Introduction} to {Digital} {Image} {Processing}},
	isbn = {0-13-480674-3},
	urldate = {2022-11-11},
	publisher = {Prentice Hall International (UK) Ltd},
	author = {Niblack, Wayne},
	year = {1986},
}

@book{castleman_digital_1996,
	address = {Upper Saddle River, New Jersey},
	title = {Digital {Image} {Processing}},
	isbn = {0-13-211467-4},
	urldate = {2022-11-11},
	publisher = {Prentice Hall},
	author = {Castleman, Kenneth},
	year = {1996},
}

@misc{chhikara_understanding_2022,
	title = {Understanding {Morphological} {Image} {Processing} and {Its} {Operations}},
	url = {https://towardsdatascience.com/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756},
	abstract = {This article illustrates Morphological Image Processing in more straightforward terms; readers can understand how Morphology works in…},
	language = {en},
	urldate = {2022-11-14},
	journal = {Medium},
	author = {Chhikara, Prateek},
	month = apr,
	year = {2022},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/6HAHIWYD/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756.html:text/html},
}

@inproceedings{tomasi_bilateral_1998,
	address = {Bombay, India},
	title = {Bilateral filtering for gray and color images},
	isbn = {978-81-7319-221-0},
	url = {http://ieeexplore.ieee.org/document/710815/},
	doi = {10.1109/ICCV.1998.710815},
	abstract = {Bilateral ﬁltering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with ﬁlters that operate on the three bands of a color image separately, a bilateral ﬁlter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard ﬁltering, bilateral ﬁltering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.},
	language = {en},
	urldate = {2022-11-15},
	booktitle = {Sixth {International} {Conference} on {Computer} {Vision} ({IEEE} {Cat}. {No}.{98CH36271})},
	publisher = {Narosa Publishing House},
	author = {Tomasi, C. and Manduchi, R.},
	year = {1998},
	pages = {839--846},
	file = {Kang et al. Line Drawing.pdf:/Users/ariakillebrewbruehl/Zotero/storage/YFG3HFYZ/Kang et al. Line Drawing.pdf:application/pdf;Tomasi and Manduchi - 1998 - Bilateral filtering for gray and color images.pdf:/Users/ariakillebrewbruehl/Zotero/storage/MM6L6YHA/Tomasi and Manduchi - 1998 - Bilateral filtering for gray and color images.pdf:application/pdf},
}

@book{hughes_computer_2014,
	edition = {Third},
	title = {Computer {Graphics} {Principle} and {Practice}},
	isbn = {978-0-321-39952-6},
	publisher = {Pearson Education},
	author = {Hughes, John and Van Dam, Andries and McGuire, Morgan and Sklar, David and Foley, James and Feiner, Steven and Akeley, Kurt},
	year = {2014},
}

@misc{mallick_why_2015,
	title = {Why does {OpenCV} use {BGR} color format ? {\textbar} {LearnOpenCV} \#},
	shorttitle = {Why does {OpenCV} use {BGR} color format ?},
	url = {https://learnopencv.com/why-does-opencv-use-bgr-color-format/},
	abstract = {One of the elements of good design is the principle of least astonishment ( a.k.a principle of least surprise). A good intuitive design makes the user not think. When you see a handle on a door, you want to pull it. When you see a door with a metal plate, you want to push it.},
	language = {en-US},
	urldate = {2022-11-19},
	author = {Mallick, Satya},
	month = sep,
	year = {2015},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/HSL8VESG/why-does-opencv-use-bgr-color-format.html:text/html},
}

@article{felzenszwalb_distance_2012,
	title = {Distance {Transforms} of {Sampled} {Functions}},
	volume = {8},
	issn = {1557-2862},
	url = {https://theoryofcomputing.org/articles/v008a019},
	doi = {10.4086/toc.2012.v008a019},
	abstract = {We describe linear-time algorithms for solving a class of problems that involve transforming a cost function on a grid using spatial information. These problems can be viewed as a generalization of classical distance transforms of binary images, where the binary image is replaced by an arbitrary function on a grid. Alternatively they can be viewed in terms of the minimum convolution of two functions, which is an important operation in grayscale morphology. A consequence of our techniques is a simple and fast method for computing the Euclidean distance transform of a binary image. Our algorithms are also applicable to Viterbi decoding, belief propagation, and optimal control.},
	language = {en},
	number = {1},
	urldate = {2023-01-26},
	journal = {Theory of Computing},
	author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
	year = {2012},
	pages = {415--428},
	file = {dt-final.pdf:/Users/ariakillebrewbruehl/Documents/thesis/readings/hedcuts/dt-final.pdf:application/pdf},
}

@misc{abecassis_opencv_2011,
	title = {{OpenCV} - {Morphological} {Skeleton}},
	url = {https://felix.abecassis.me/2011/09/opencv-morphological-skeleton/},
	author = {Abecassis, Félix},
	month = sep,
	year = {2011},
}

@misc{noauthor_lift_nodate,
	title = {Lift a subject from the photo background on {iPhone}},
	url = {https://support.apple.com/en-gb/guide/iphone/iphfe4809658/ios},
	abstract = {Cut out the subject of a photo from the background of a photo to copy and share in other documents and apps on iPhone.},
	language = {en},
	urldate = {2023-02-25},
	journal = {Apple Support},
	file = {Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/CR9FGXA9/ios.html:text/html},
}

@article{kim_feature-guided_2008,
	title = {Feature-guided {Image} {Stippling}},
	volume = {27},
	abstract = {This paper presents an automatic method for producing stipple renderings from photographs, following the style of professional hedcut illustrations. For effective depiction of image features, we introduce a novel dot placement algorithm which adapts stipple dots to the local shapes. The core idea is to guide the dot placement along ‘feature ﬂow’ extracted from the feature lines, resulting in a dot distribution that conforms to feature shapes. The sizes of dots are also adaptively determined from the input image for proper tone representation. Experimental results show that such feature-guided stippling leads to the production of stylistic and feature-emphasizing dot illustrations.},
	language = {en},
	number = {4},
	journal = {Eurographics Symposium on Rendering},
	author = {Kim, Dongyeon and Son, Minjung and Lee, Yunjin and Kang, Henry and Lee, Seungyong},
	year = {2008},
	pages = {9},
	file = {kang_egsr08.pdf:/Users/ariakillebrewbruehl/Documents/thesis/readings/hedcuts/kang_egsr08.pdf:application/pdf},
}

@misc{noauthor_opencv_nodate,
	title = {{OpenCV}: {Color} conversions},
	url = {https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html},
	urldate = {2023-03-06},
	file = {OpenCV\: Color conversions:/Users/ariakillebrewbruehl/Zotero/storage/3Q9XYJR5/imgproc_color_conversions.html:text/html},
}

@inproceedings{rosin_benchmarking_2017,
	address = {Los Angeles California},
	title = {Benchmarking non-photorealistic rendering of portraits},
	isbn = {978-1-4503-5081-5},
	url = {https://dl.acm.org/doi/10.1145/3092919.3092921},
	doi = {10.1145/3092919.3092921},
	abstract = {We present a set of images for helping NPR practitioners evaluate their image-based portrait stylisation algorithms. Using a standard set both facilitates comparisons with other methods and helps ensure that presented results are representative. We give two levels of di culty, each consisting of 20 images selected systematically so as to provide good coverage of several possible portrait characteristics. We applied three existing portrait-speci c stylisation algorithms, two general-purpose stylisation algorithms, and one general learning based stylisation algorithm to the rst level of the benchmark, corresponding to the type of constrained images that have o en been used in portrait-speci c work. We found that the existing methods are generally e ective on this new image set, demonstrating that level one of the benchmark is tractable; challenges remain at level two. Results revealed several advantages conferred by portrait-speci c algorithms over general-purpose algorithms: portrait-speci c algorithms can use domain-speci c information to preserve key details such as eyes and to eliminate extraneous details, and they have more scope for semantically meaningful abstraction due to the underlying face model. Finally, we provide some thoughts on systematically extending the benchmark to higher levels of di culty.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Proceedings of the {Symposium} on {Non}-{Photorealistic} {Animation} and {Rendering}},
	publisher = {ACM},
	author = {Rosin, Paul L. and Mould, David and Berger, Itamar and Collomosse, John and Lai, Yu-Kun and Li, Chuan and Li, Hua and Shamir, Ariel and Wand, Michael and Wang, Tinghuai and Winnemöller, Holger},
	month = jul,
	year = {2017},
	pages = {1--12},
	file = {Rosin et al. - 2017 - Benchmarking non-photorealistic rendering of portr.pdf:/Users/ariakillebrewbruehl/Zotero/storage/PX4PBWRC/Rosin et al. - 2017 - Benchmarking non-photorealistic rendering of portr.pdf:application/pdf},
}

@inproceedings{rosin_non-photorealistic_2015,
	address = {Istanbul, Turkey},
	title = {Non-{Photorealistic} {Rendering} of {Portraits}},
	abstract = {We describe an image-based non-photorealistic rendering pipeline for creating portraits in two styles: The ﬁrst is a somewhat “puppet” like rendering, that treats the face like a relatively uniform smooth surface, with the geometry being emphasised by shading. The second style is inspired by the artist Julian Opie, in which the human face is reduced to its essentials, i.e. homogeneous skin, thick black lines, and facial features such as eyes and the nose represented in a cartoon manner. Our method is able to automatically generate these stylisations without requiring the input images to be tightly cropped, direct frontal view, and moreover perform abstraction while maintaining the distinctiveness of the portraits (i.e. they should remain recognisable).},
	language = {en},
	author = {Rosin, Paul L and Lai, Yu-Kun},
	month = mar,
	year = {2015},
	file = {Rosin and Lai - Non-Photorealistic Rendering of Portraits.pdf:/Users/ariakillebrewbruehl/Zotero/storage/3MK5VLFF/Rosin and Lai - Non-Photorealistic Rendering of Portraits.pdf:application/pdf},
}

@article{rhee_cartoon-like_2013,
	title = {Cartoon-like {Avatar} {Generation} {Using} {Facial} {Component} {Matching}},
	volume = {8},
	abstract = {Nowadays, avatars are widely used in games and Internet environments. Especially, video game consoles such as Wii (Nintendo) use avatars for representing the user's alter ego. There are several ways to generate avatars. Most existing games or Internet services provide manual systems for generating avatars. Many researchers have suggested automatic avatar generation methods, most of which generate avatars by simplifying images using non-photorealistic rendering techniques.},
	language = {en},
	number = {4},
	journal = {International Journal of Multimedia and Ubiquitous Engineering},
	author = {Rhee, Chi-Hyoung and Lee, Chang Ha},
	year = {2013},
	file = {Rhee and Lee - 2013 - Cartoon-like Avatar Generation Using Facial Compon.pdf:/Users/ariakillebrewbruehl/Zotero/storage/R3DILNJ3/Rhee and Lee - 2013 - Cartoon-like Avatar Generation Using Facial Compon.pdf:application/pdf},
}

@article{kasao_algorithmic_2006,
	title = {Algorithmic {Painter}: a {NPR} method to generate various styles of painting},
	volume = {22},
	issn = {0178-2789, 1432-2315},
	shorttitle = {Algorithmic {Painter}},
	url = {http://link.springer.com/10.1007/s00371-005-0353-8},
	doi = {10.1007/s00371-005-0353-8},
	language = {en},
	number = {1},
	urldate = {2023-03-08},
	journal = {The Visual Computer},
	author = {Kasao, Atsushi and Miyata, Kazunori},
	month = jan,
	year = {2006},
	pages = {14--27},
	file = {Kasao and Miyata - 2006 - Algorithmic Painter a NPR method to generate vari.pdf:/Users/ariakillebrewbruehl/Zotero/storage/65KC7A5L/Kasao and Miyata - 2006 - Algorithmic Painter a NPR method to generate vari.pdf:application/pdf},
}

@inproceedings{ostromoukhov_digital_1999,
	address = {Not Known},
	title = {Digital facial engraving},
	isbn = {978-0-201-48560-8},
	url = {http://portal.acm.org/citation.cfm?doid=311535.311604},
	doi = {10.1145/311535.311604},
	abstract = {This contribution introduces the basic techniques for digital facial engraving, which imitates traditional copperplate engraving. Inspired by traditional techniques, we ﬁrst establish a set of basic rules thanks to which separate engraving layers are built on the top of the original photo. Separate layers are merged according to simple merging rules and according to range shift/scale masks specially introduced for this purpose. We illustrate the introduced technique by a set of black/white and color engravings, showing different features such as engraving-speciﬁc image enhancements, mixing different regular engraving lines with mezzotint, irregular perturbations of engraving lines etc. We introduce the notion of engraving style which comprises a set of separate engraving layers together with a set of associated range shift/scale masks. The engraving style helps to port the look and feel of one engraving to another. Once different libraries of pre-deﬁned mappable engraving styles and an appropriate user interface are added to the basic system, producing a decent gravure starting from a simple digital photo will be a matter of seconds. The engraving technique described in this contribution opens new perspectives for digital art, adding unprecedented power and precision to the engraver’s work.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Proceedings of the 26th annual conference on {Computer} graphics and interactive techniques  - {SIGGRAPH} '99},
	publisher = {ACM Press},
	author = {Ostromoukhov, Victor},
	year = {1999},
	pages = {417--424},
	file = {Ostromoukhov - 1999 - Digital facial engraving.pdf:/Users/ariakillebrewbruehl/Zotero/storage/3LGZWH4F/Ostromoukhov - 1999 - Digital facial engraving.pdf:application/pdf},
}

@article{fazelpour_algorithmic_2021,
	title = {Algorithmic bias: {Senses}, sources, solutions},
	volume = {16},
	issn = {1747-9991},
	shorttitle = {Algorithmic bias},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/phc3.12760},
	doi = {10.1111/phc3.12760},
	abstract = {Data-driven algorithms are widely used to make or assist decisions in sensitive domains, including healthcare, social services, education, hiring, and criminal justice. In various cases, such algorithms have preserved or even exacerbated biases against vulnerable communities, sparking a vibrant field of research focused on so-called algorithmic biases. This research includes work on identification, diagnosis, and response to biases in algorithm-based decision-making. This paper aims to facilitate the application of philosophical analysis to these contested issues by providing an overview of three key topics: What is algorithmic bias? Why and how can it occur? What can and should be done about it? Throughout, we highlight connections—both actual and potential—with philosophical ideas and concerns.},
	language = {en},
	number = {8},
	urldate = {2023-03-08},
	journal = {Philosophy Compass},
	author = {Fazelpour, Sina and Danks, David},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/phc3.12760},
	pages = {e12760},
	file = {Full Text PDF:/Users/ariakillebrewbruehl/Zotero/storage/K5Q85U4D/Fazelpour and Danks - 2021 - Algorithmic bias Senses, sources, solutions.pdf:application/pdf;Snapshot:/Users/ariakillebrewbruehl/Zotero/storage/ZHJAJ4QL/phc3.html:text/html},
}

@incollection{rosin_npr_2013,
	address = {London},
	edition = {1st},
	title = {{NPR} in the {Wild}},
	isbn = {978-1-4471-4518-9},
	url = {https://doi.org/10.1007/978-1-4471-4519-6},
	booktitle = {Image and {Video}-{Based} {Artistic} {Stylisation}},
	publisher = {Springer},
	author = {Winnemöller, Holger},
	editor = {Rosin, Paul and Collomosse, John},
	year = {2013},
}

@misc{aguilar_how_2010,
	title = {How {WSJ} {Stipple} {Drawings} are {Made}},
	url = {https://www.wsj.com/video/how-wsj-stipple-drawings-are-made/91955BD8-9F31-4E50-AEF1-26A61B3AA2FB.html},
	abstract = {Brian Aguilar walks through the history of the WSJ's beloved stipple drawings and has the paper's artists explain how the so-called hedcuts are made.},
	author = {Aguilar, Brian},
	month = mar,
	year = {2010},
}

@incollection{halper_towards_2003,
	title = {Towards an {Understanding} of the {Psychology} of {Non}-{Photorealistic} {Rendering}},
	volume = {11},
	isbn = {978-3-8244-4550-9},
	url = {https://doi.org/10.1007/978-3-322-81318-3_9},
	booktitle = {Computational {Visualistics}, {Media} {Informatics}, and {Virtual} {Communities}},
	publisher = {Deutscher Universitätsverlag},
	author = {Halper, N. and Mellin, M. and Herrmann, C. S. and Linneweber, V. and Strothotte, T.},
	year = {2003},
}

@incollection{schumann_assessing_1996,
	address = {New York, NY, USA},
	title = {Assessing the {Effect} of {Non}-{Photorealistic} {Rendered} {Images} in {CAD}},
	isbn = {0-89791-777-4},
	url = {https://doi.org/10.1145/238386.238398},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schumann, Jutta and Strothotte, Thomas and Laser, Stefan and Raab, Andreas},
	year = {1996},
}

@article{duke_rendering_2003,
	title = {Rendering and {Affect}},
	volume = {22},
	doi = {https://doi.org/10.1111/1467-8659.00683},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Duke, D. J. and Barnard, P. J. and Halper, N. and Mellin, M.},
	month = nov,
	year = {2003},
	pages = {359--368},
}

@incollection{isenberg_evaluating_2013,
	address = {London},
	edition = {1st},
	title = {Evaluating and {Validating} {Non}-photorealistic and {Illustrative} {Rendering}},
	isbn = {1-283-90993-6},
	booktitle = {Image and {Video}-{Based} {Artistic} {Stylisation}},
	publisher = {Springer},
	author = {Isenberg, Tobias},
	editor = {Rosin, Paul and Collomosse, John},
	year = {2013},
}

@article{maciejewski_measuring_2008,
	title = {Measuring {Stipple} {Aesthetics} in {Hand}-{Drawn} and {Computer}-{Generated} {Images}},
	volume = {28},
	issn = {0272-1716},
	url = {http://ieeexplore.ieee.org/document/4459866/},
	doi = {10.1109/MCG.2008.35},
	language = {en},
	number = {2},
	urldate = {2023-03-12},
	journal = {IEEE Computer Graphics and Applications},
	author = {Maciejewski, Ross and Isenberg, Tobias and Andrews, William M. and Ebert, David S. and Sousa, Mario Costa and Chen, Wei},
	month = mar,
	year = {2008},
	pages = {62--74},
	file = {Maciejewski et al. - 2008 - Measuring Stipple Aesthetics in Hand-Drawn and Com.pdf:/Users/ariakillebrewbruehl/Zotero/storage/RRFLYNED/Maciejewski et al. - 2008 - Measuring Stipple Aesthetics in Hand-Drawn and Com.pdf:application/pdf},
}

@incollection{kang_coherent_2007,
	series = {{NPAR} '07},
	title = {Coherent {Line} {Drawing}},
	isbn = {978-1-59593-624-0},
	url = {https://doi.org/10.1145/1274871.1274878},
	booktitle = {Proceedings of the 5th {International} {Symposium} on {Non}-{Photorealistic} {Animation} and {Rendering}},
	publisher = {Association for Computing Machinery},
	author = {Kang, Henry and Lee, Seungyong and Chui, Charles .},
	month = aug,
	year = {2007},
	pages = {43--50},
}

@misc{fisher_feature_2003,
	title = {Feature {Detectors} - {Sobel} {Edge} {Detector}},
	url = {https://homepages.inf.ed.ac.uk/rbf/HIPR2/sobel.htm},
	urldate = {2023-03-14},
	author = {Fisher, R. and Perkins, S. and Walker, A. and Wolfart, E.},
	year = {2003},
	file = {Feature Detectors - Sobel Edge Detector:/Users/ariakillebrewbruehl/Zotero/storage/AL7TN9CK/sobel.html:text/html},
}

@misc{noauthor_opencv_nodate-1,
	title = {{OpenCV}: {Image} {Thresholding}},
	url = {https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html},
	urldate = {2023-03-14},
	file = {OpenCV\: Image Thresholding:/Users/ariakillebrewbruehl/Zotero/storage/NEZWHT3G/tutorial_py_thresholding.html:text/html},
}

@misc{phillips_additive_2022,
	title = {Additive vs. {Substractive} {Color} {Models}},
	url = {https://www.hunterlab.com/blog/additive-vs-subtractive-color-models/},
	urldate = {2023-03-28},
	journal = {HunterLab},
	author = {Phillips, Ken},
	month = oct,
	year = {2022},
	file = {hunterlab.com/blog/additive-vs-subtractive-color-models/:/Users/ariakillebrewbruehl/Zotero/storage/JATKZPJV/additive-vs-subtractive-color-models.html:text/html},
}

@misc{noauthor_what_nodate,
	title = {What {Is} {Image} {Filtering} in the {Spatial} {Domain}? - {MATLAB} \& {Simulink}},
	url = {https://www.mathworks.com/help/images/what-is-image-filtering-in-the-spatial-domain.html},
	urldate = {2023-03-31},
	journal = {MathWorks},
	file = {What Is Image Filtering in the Spatial Domain? - MATLAB & Simulink:/Users/ariakillebrewbruehl/Zotero/storage/ZURQ4VRP/what-is-image-filtering-in-the-spatial-domain.html:text/html},
}

@article{aurenhammer_voronoi_1991,
	title = {Voronoi diagrams—a survey of a fundamental geometric data structure},
	volume = {23},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/116873.116880},
	doi = {10.1145/116873.116880},
	language = {en},
	number = {3},
	urldate = {2023-04-20},
	journal = {ACM Computing Surveys},
	author = {Aurenhammer, Franz},
	month = sep,
	year = {1991},
	pages = {345--405},
	file = {Aurenhammer - 1991 - Voronoi diagrams—a survey of a fundamental geometr.pdf:/Users/ariakillebrewbruehl/Zotero/storage/5ADS7CQE/Aurenhammer - 1991 - Voronoi diagrams—a survey of a fundamental geometr.pdf:application/pdf},
}

@misc{kherada_opencv_nodate,
	title = {{OpenCV}: samples/cpp/create\_mask.cpp},
	url = {https://docs.opencv.org/4.x/db/d75/samples_2cpp_2create_mask_8cpp-example.html#a25},
	urldate = {2023-04-20},
	author = {Kherada, Siddharth},
	file = {OpenCV\: samples/cpp/create_mask.cpp:/Users/ariakillebrewbruehl/Zotero/storage/NBSQUJCI/samples_2cpp_2create_mask_8cpp-example.html:text/html},
}
